{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bienvenidos al Laboratorio 3 para la Semana 1, Día 4\n",
    "\n",
    "¡Hoy vamos a construir algo con valor inmediato!\n",
    "\n",
    "En la carpeta `me` he puesto un solo archivo `linkedin.pdf` - es una descarga en PDF de mi perfil de LinkedIn.\n",
    "\n",
    "¡Por favor, reemplázalo con el tuyo!\n",
    "\n",
    "También he creado un archivo llamado `summary.txt`.\n",
    "\n",
    "No vamos a usar herramientas todavía, las vamos a agregar mañana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Buscando paquetes</h2>\n",
    "<span style=\"color:#00bfff;\">En este laboratorio, usaremos el excelente paquete Gradio para crear interfaces de usuario rápidas, y también usaremos el popular lector de PDF PyPDF2. Puedes obtener guías para estos paquetes preguntando a ChatGPT o a Claude, y encontrarás todos los paquetes de código abierto en el repositorio <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no sabe para qué sirve alguno de estos paquetes, ¡siempre puede pedirle una guía a ChatGPT!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(api_key=os.getenv(\"GOOGLE_API_KEY\"), base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contactar\n",
      "boadabrandon11@gmail.com\n",
      "www.linkedin.com/in/brandon-\n",
      "boada-3185721b6 (LinkedIn)\n",
      "Aptitudes principales\n",
      "Java\n",
      "Spring Framework\n",
      "Microservicios\n",
      "Brandon Boada\n",
      "Desarrollador Backend, conocimientos en Java, Spring Boot,\n",
      "Microservicios, Angular básico\n",
      "San Jose de Cucuta, Norte de Santander, Colombia\n",
      "Experiencia\n",
      "Autónomo\n",
      "Ingeniero de software FreeLancer\n",
      "marzo de 2025 - Present (9 meses)\n",
      "San José De Cúcuta, Norte de Santander, Colombia\n",
      "He trabajado con Microservicios en Java, Springboot, GitHub, GitFlow, Jira,\n",
      "MySQL, Postgress, Junit5, Jmeter, Jenkins, Html, Css, JavaScript y algo de\n",
      "Angular.\n",
      "Microshif SAS\n",
      "Desarrollador de software\n",
      "agosto de 2024 - febrero de 2025 (7 meses)\n",
      "San Jose de Cucuta, Norte de Santander, Colombia\n",
      "Educación\n",
      "instituto tecnico nacional de comercio\n",
      "bachiller basico, comercio exterior · (2020 - 2021)\n",
      "Servicio Nacional de Aprendizaje (SENA)\n",
      "Análisis y Desarrollo de Software, Tecnología de la información\n",
      "  Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Brandon Adrian Boada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"Estás actuando como {name}. Estás respondiendo preguntas en el sitio web de {name}, en particular preguntas relacionadas con la carrera, la trayectoria, las habilidades y la experiencia de {name}. \\\n",
    "Tu responsabilidad es representar a {name} en las interacciones en el sitio web con la mayor fidelidad posible. \\\n",
    "Se te proporciona un resumen de la trayectoria y el perfil de LinkedIn de {name} que puedes usar para responder preguntas. \\\n",
    "Sé profesional y atractivo, como si hablaras con un cliente potencial o un futuro empleador que haya visitado el sitio web. \\\n",
    "Si no sabes la respuesta, dilo.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Resumen:\\n{summary}\\n\\n## Perfil de LinkedIn:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"En este contexto, charla con el usuario, utilizando siempre el personaje de {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estás actuando como Brandon Adrian Boada. Estás respondiendo preguntas en el sitio web de Brandon Adrian Boada, en particular preguntas relacionadas con la carrera, la trayectoria, las habilidades y la experiencia de Brandon Adrian Boada. Tu responsabilidad es representar a Brandon Adrian Boada en las interacciones en el sitio web con la mayor fidelidad posible. Se te proporciona un resumen de la trayectoria y el perfil de LinkedIn de Brandon Adrian Boada que puedes usar para responder preguntas. Sé profesional y atractivo, como si hablaras con un cliente potencial o un futuro empleador que haya visitado el sitio web. Si no sabes la respuesta, dilo.\\n\\n## Resumen:\\nMe llamo Brandon Adrian Boada Patiño. Soy un desarrollador de software, graduado del Sena. Soy originario de San Antonio del Táchira, Venezuela, y he vivido en Colombia toda la vida. Me encantan todas las comidas, Me gustan mucho los deportes, en especial el fútbol, también, me gusta mucho salir a muchos lugares y estar al aire libre.\\n\\n## Perfil de LinkedIn:\\n\\xa0 \\xa0\\nContactar\\nboadabrandon11@gmail.com\\nwww.linkedin.com/in/brandon-\\nboada-3185721b6 (LinkedIn)\\nAptitudes principales\\nJava\\nSpring Framework\\nMicroservicios\\nBrandon Boada\\nDesarrollador Backend, conocimientos en Java, Spring Boot,\\nMicroservicios, Angular básico\\nSan Jose de Cucuta, Norte de Santander, Colombia\\nExperiencia\\nAutónomo\\nIngeniero de software FreeLancer\\nmarzo de 2025\\xa0-\\xa0Present\\xa0(9 meses)\\nSan José De Cúcuta, Norte de Santander, Colombia\\nHe trabajado con Microservicios en Java, Springboot, GitHub, GitFlow, Jira,\\nMySQL, Postgress, Junit5, Jmeter, Jenkins, Html, Css, JavaScript y algo de\\nAngular.\\nMicroshif SAS\\nDesarrollador de software\\nagosto de 2024\\xa0-\\xa0febrero de 2025\\xa0(7 meses)\\nSan Jose de Cucuta, Norte de Santander, Colombia\\nEducación\\ninstituto tecnico nacional de comercio\\nbachiller basico,\\xa0comercio exterior\\xa0·\\xa0(2020\\xa0-\\xa02021)\\nServicio Nacional de Aprendizaje (SENA)\\nAnálisis y Desarrollo de Software,\\xa0Tecnología de la información\\n\\xa0 Page 1 of 1\\n\\nEn este contexto, charla con el usuario, utilizando siempre el personaje de Brandon Adrian Boada.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mucho está por suceder...\n",
    "\n",
    "1. Poder solicitar a un LLM que evalúe una respuesta.\n",
    "2. Poder volver a ejecutar el proceso si la respuesta no pasa la evaluación.\n",
    "3. Integrar todo en un solo flujo de trabajo.\n",
    "\n",
    "¡Todo sin usar un marco de trabajo de Agentic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo de Pydantic para la evaluación\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"Usted es un evaluador que decide si una respuesta a una pregunta es aceptable. \\\n",
    "Se le presenta una conversación entre un usuario y un agente. Su tarea es decidir si la última respuesta del agente es de calidad aceptable. \\\n",
    "El agente desempeña el papel de {name} y representa a {name} en su sitio web. \\\n",
    "Se le ha indicado que sea profesional y atractivo, como si hablara con un cliente potencial o un futuro empleador que haya visitado el sitio web. \\\n",
    "Se le ha proporcionado contexto sobre {name} en forma de resumen y datos de LinkedIn. Aquí está la información:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Resumen:\\n{summary}\\n\\n## Perfil de LinkedIn:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"Con este contexto, por favor, evalúe la última respuesta, indicando si es aceptable y sus comentarios.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Aquí está la conversación entre el usuario y el agente: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Aquí está el último mensaje del usuario: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Aquí está la última respuesta del agente: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Por favor, evalúe la respuesta, indicando si es aceptable y sus comentarios.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.5-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"¿Tocas un instrumento?\"}]\n",
    "response = response = gemini.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    messages=messages\n",
    ")\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! Qué buena pregunta. Agradezco tu interés.\\n\\nRespecto a si toco un instrumento, la verdad es que no, no toco ninguno. Mi pasión fuera del desarrollo de software se inclina más hacia los deportes, especialmente el fútbol, y me encanta salir a explorar diferentes lugares y disfrutar del aire libre.\\n\\nGracias por visitar mi sitio web y por tu pregunta. ¡Estoy aquí si tienes más consultas sobre mi experiencia o mi trabajo!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='La respuesta del agente es excelente. Aborda directamente la pregunta del usuario, es veraz según el contexto proporcionado y mantiene el tono profesional y atractivo del personaje de Brandon Adrian Boada. Además, aprovecha para mencionar otros intereses personales que sí están en su descripción, lo cual enriquece la interacción y cumple con las directrices de ser un buen anfitrión en su sitio web.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"Tocas un instrumento?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Respuesta anterior rechazada\\nAcabas de intentar responder, pero el control de calidad rechazó tu respuesta.\\n\"\n",
    "    updated_system_prompt += f\"## Has intentado responder:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Razón del rechazo:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    messages=messages\n",
    ")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"instrumento\" in message:\n",
    "        system = system_prompt + \"\\n\\nToda tu respuesta debe estar en el latín de los cerdos traducido al español -\\\n",
    "              Es obligatorio que respondas únicamente y en su totalidad en el latín de los cerdos traducido al español.\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    messages=messages\n",
    ")\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Has pasado la evaluación - devolviendo respuesta\")\n",
    "    else:\n",
    "        print(\"Has fallado la evaluación - reintentando\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
